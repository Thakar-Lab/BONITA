# import necessary modules
import argparse as argparse
import operator
import networkx as nx
import pickle
from ctypes import *
from simulation import paramClass, modelClass, NPsync
from utils import genInitValueList, setupEmptyKOKI, writeModel
from GA import GAsearchModel, localSearch
from analysis_accuracy import modelHolder
from pathway_analysis_score_nodes import *
import subprocess
import time
import glob

# calculate importance scores
def calcImportance_mod(individual,params,model, sss,knockoutLists, knockinLists, boolC):
	importanceScores=[] # holder for impact scores
	print("Model nodelist: " + str(model.nodeList))
	print("Node" + "\t" + "Importance Scores")
	# loop over all nodes
	for node in range(len(model.nodeList)):
		SSEs=[] # add SSE across samples
		nodeValues=[sss[j][model.nodeList[node]]for j in range(0,len(sss))]
		#nodeValues=[sss[j][node]for j in range(0,len(sss))]
		for j in range(0,len(sss)): # knock each node out and in to observe differences
			ss=sss[j]
			initValues=list(model.initValueList[j])
			knockerOuter=list(knockoutLists[j])
			knockerOuter.append(node) # knock out node
			boolValues1=NPsync(individual, model, params.cells, initValues, params, knockerOuter, knockinLists[j], boolC)
			knockerInner=list(knockinLists[j])
			knockerInner.append(node) # knock in node
			boolValues2=NPsync(individual, model, params.cells, initValues, params, knockoutLists[j], knockerInner, boolC)
			# find difference between knockout and knockin
			SSE=0
			for i in range(0, len(model.nodeList)):
				SSE+=(boolValues1[i]-boolValues2[i])**2
			SSEs.append(SSE)
		print(str(model.nodeList[node]) + "\t" + str(sum(SSEs)))
		importanceScores.append(sum(SSEs))
	return importanceScores


if __name__ == '__main__':

	start_time = time.time()

	# read in arguments from shell scripts

	parser = argparse.ArgumentParser()
	parser.add_argument("graph")
	parser.add_argument("iterNum")
	results = parser.parse_args()
	graphName=results.graph
	print(graphName)
	iterNum=int(results.iterNum)
	name=graphName[:-8]+'_'+results.iterNum
	graph = nx.read_gpickle(str(graphName[:-8])+".gpickle")


	#name = "temp"

	#PROCESS OUTPUTS: unpack all pickles generated by the processes spawned by runAllNodes

	outputs = glob.glob("*local1.pickle")
	print("list of outputs: " + str(outputs))

	equivs=[]
	individual=[]
	devs=[]

	for output in outputs:
		individual.extend(output[0])
		equivs.append(output[1])
		devs.append(output[2])

	print("Equivalent rules: " + str(equivs))

	#open GA model
	GAmodels=glob.glob("*_GAmodel.pickle")
	for GAmodel in GAmodels:

		storeModel1, bruteOut1, knockoutLists, knockinLists = pickle.load(open(GAmodel, "rb"))
		model1 = modelHolder(storeModel1)

		# read in C function to run simulations
		updateBooler=cdll.LoadLibrary('./simulator.so')
		boolC=updateBooler.syncBool

		# load data
		sampleList=pickle.Unpickler(open( graphName[:-8]+'_sss.pickle', "rb" )).load()
		#sampleList = pickle.Unpickler(open("WP23_edgeList_edited.txt_net_2.rules_sss.pickle", "rb" )).load()
		print("Sample List: " + str(sampleList))

		# set up parameters of run, model
		params=paramClass()
		model1.modelHolder_updateCpointers()

		# calculate importance scores and output
		scores1=calcImportance_mod(bruteOut1,params,model1, sampleList,knockoutLists, knockinLists, boolC)
		pickle.dump(scores1, open(name+"_scores1.pickle", "wb"))

		# write rules
		with open(name+"_rules.txt", "w") as text_file:
			text_file.write(writeModel(bruteOut1, model1))
		print("--- %s seconds ---" % (time.time() - start_time))

